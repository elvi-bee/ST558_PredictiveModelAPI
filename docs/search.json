[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ST 558 Final Project",
    "section": "",
    "text": "If you are not automatically redirected, click here for the EDA page."
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "This project explores data on Diabetes. The original data were obtained from the CDC’s Behavioral Risk Factor Surveillance System (BRFSS), a health-related telephone survey that is collected annually by the CDC. The data contain self-reported health and lifestyle information and include 22 variables related to chronic disease, physical activity, general health, demographics, and access to health care. The primary outcome of interest in this project is ‘Diabetes_binary’, a binary indicator where:\n\n0 = No diabetes\n1 = Diabetes\n\nThe majority of remaining variables are coded as binary (0/1) indicators (e.g., HighBP, HighChol, Stroke, Smoker), with some coded as ordinal categories (e.g., Age, Education, Income) or counts (e.g., MentHlth, PhysHlth).\nDuring the Exploratory Data Analysis many variables showed interesting relationships with Diabetes prevalence. Among binary variables, high blood pressure, high cholesterol, heart disease or attack status, physical activity, and difficulty walking all showed relationships with diabetes prevalence. Among numeric variables, BMI and physical health showed the strongest relationships. Among ordinal variables, age and general health appeared to have stronger relations with diabetes that other ordinal variables.\nClick here to go back to the EDA page.\nIn this section we will proceed to construct two models using selected variables from the aforementioned data.\n\n\n\n\nA classification tree is a decision tree model. It predicts a categorical outcome (in this case, diabetes yes/no) by splitting the data into groups. At each split in the tree, the model chooses the predictor and cutoff that best separates classes. In other words, it predicts the majority class inside each leaf. Classification trees are easy to visualize and interpret but can be sensitive to small changes in the data. They are good for understanding patterns, but not necessarily for maximizing accuracy.\n\n\n\nA Random Forest model is a type of ensemble model. It builds many classification trees on bootstrapped data, meaning it re-samples data with replacement. Then it grows a full decision tree, repeats the process many times, and averages predictions. By averaging across many trees, random forest models reduce over-fitting, improve accuracy, capture nonlinear relationships more effectively than a single tree, and come up with more stable predictions. Random Forests and Ensemble models in general can be harder to explain and visualize than simpler models.\n\n\n\n\nBased on the results of the Exploratory Data Analysis, five predictors were selected that showed the strongest relationships with diabetes. High blood pressure and high cholesterol were two of the most strongly associated binary indicators. Difficulty walking was another strong binary predictor. BMI was the strongest continuous predictor. Finally, age showed a clear relationship, with diabetes prevalence increasing steadily across older age groups.\nSummary of variables that were selected:\n\nHigh Blood Pressure (high_bp): binary, 0 = no high BP/ 1 = high BP\nHigh Cholesterol (high_chol): binary, 0 = no high Chol/ 1 = high Chol\nBMI (bmi): continuous, 12 - 98\nAge (age): ordinal, 13-level age categories, 1 = 18-24; 9 = 60-64; 13 = 80 or older\nDifficulty Walking (diff_walk): binary, 0 = no, 1 = yes"
  },
  {
    "objectID": "Modeling.html#introduction",
    "href": "Modeling.html#introduction",
    "title": "Modeling",
    "section": "",
    "text": "This project explores data on Diabetes. The original data were obtained from the CDC’s Behavioral Risk Factor Surveillance System (BRFSS), a health-related telephone survey that is collected annually by the CDC. The data contain self-reported health and lifestyle information and include 22 variables related to chronic disease, physical activity, general health, demographics, and access to health care. The primary outcome of interest in this project is ‘Diabetes_binary’, a binary indicator where:\n\n0 = No diabetes\n1 = Diabetes\n\nThe majority of remaining variables are coded as binary (0/1) indicators (e.g., HighBP, HighChol, Stroke, Smoker), with some coded as ordinal categories (e.g., Age, Education, Income) or counts (e.g., MentHlth, PhysHlth).\nDuring the Exploratory Data Analysis many variables showed interesting relationships with Diabetes prevalence. Among binary variables, high blood pressure, high cholesterol, heart disease or attack status, physical activity, and difficulty walking all showed relationships with diabetes prevalence. Among numeric variables, BMI and physical health showed the strongest relationships. Among ordinal variables, age and general health appeared to have stronger relations with diabetes that other ordinal variables.\nClick here to go back to the EDA page.\nIn this section we will proceed to construct two models using selected variables from the aforementioned data.\n\n\n\n\nA classification tree is a decision tree model. It predicts a categorical outcome (in this case, diabetes yes/no) by splitting the data into groups. At each split in the tree, the model chooses the predictor and cutoff that best separates classes. In other words, it predicts the majority class inside each leaf. Classification trees are easy to visualize and interpret but can be sensitive to small changes in the data. They are good for understanding patterns, but not necessarily for maximizing accuracy.\n\n\n\nA Random Forest model is a type of ensemble model. It builds many classification trees on bootstrapped data, meaning it re-samples data with replacement. Then it grows a full decision tree, repeats the process many times, and averages predictions. By averaging across many trees, random forest models reduce over-fitting, improve accuracy, capture nonlinear relationships more effectively than a single tree, and come up with more stable predictions. Random Forests and Ensemble models in general can be harder to explain and visualize than simpler models.\n\n\n\n\nBased on the results of the Exploratory Data Analysis, five predictors were selected that showed the strongest relationships with diabetes. High blood pressure and high cholesterol were two of the most strongly associated binary indicators. Difficulty walking was another strong binary predictor. BMI was the strongest continuous predictor. Finally, age showed a clear relationship, with diabetes prevalence increasing steadily across older age groups.\nSummary of variables that were selected:\n\nHigh Blood Pressure (high_bp): binary, 0 = no high BP/ 1 = high BP\nHigh Cholesterol (high_chol): binary, 0 = no high Chol/ 1 = high Chol\nBMI (bmi): continuous, 12 - 98\nAge (age): ordinal, 13-level age categories, 1 = 18-24; 9 = 60-64; 13 = 80 or older\nDifficulty Walking (diff_walk): binary, 0 = no, 1 = yes"
  },
  {
    "objectID": "Modeling.html#modeling",
    "href": "Modeling.html#modeling",
    "title": "Modeling",
    "section": "2. Modeling",
    "text": "2. Modeling\nClassification Tree Random Forest Models will be constructed and tested to determine the best model for the data.\n\n2.1 Data Preparation\n\n2.1.1 Creating Training and Test Splits and Cross Validation\nThe data was split into a training (70% of the data) and test set (30% of the data). Then, 5-fold cross-validation is implemented to aid with selection of the ultimate best model.\n\n# split training and test data\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n✔ broom        1.0.9     ✔ rsample      1.3.1\n✔ dials        1.4.2     ✔ tailor       0.1.0\n✔ infer        1.0.9     ✔ tune         2.0.1\n✔ modeldata    1.5.1     ✔ workflows    1.3.0\n✔ parsnip      1.3.3     ✔ workflowsets 1.1.1\n✔ recipes      1.3.1     ✔ yardstick    1.3.2\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(readxl)\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(rpart.plot)\n\nLoading required package: rpart\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\n# Read in data and clean column names\ndata &lt;- read.csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\",header=TRUE) |&gt;\n  clean_names()\nset.seed(11)\n\n# Factors\ndata &lt;- data |&gt;\n  mutate(diabetes_binary = factor(diabetes_binary))\n\n# 70/30 split\ndiab_split &lt;- initial_split(data, prop = 0.70, strata = diabetes_binary)\ndiab_train &lt;- training(diab_split)\ndiab_test  &lt;- testing(diab_split)\n\n# 5-fold cross-validation\ndiab_folds &lt;- vfold_cv(diab_train, v = 5, strata = diabetes_binary)\n\n\n\n2.1.2 Recipe\nDefine the recipe using the following 5 predictors: high_bp, high_chol, diff_walk, bmi, age. Additionally, this step creates dummy variables for nominal predictors and normalizes numeric predictors.\n\n# Recipe \ndiab_rec &lt;- recipe(\n  diabetes_binary ~ high_bp + high_chol + diff_walk + bmi + age,\n  data = diab_train\n) |&gt;\n  step_dummy(all_nominal_predictors()) |&gt;\n  step_normalize(all_numeric_predictors())\n\n\n\n\n2.3 Classification Tree\n\n# Specify model\ntree_spec &lt;- decision_tree(\n  tree_depth = tune(),\n  cost_complexity = tune(),\n  min_n = 20\n) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\n# Workflow\ntree_wf &lt;- workflow() |&gt;\n  add_recipe(diab_rec) |&gt;\n  add_model(tree_spec)\n\n# Tuning grid and 5-fold cv with log loss, accuracy, roc_auc\ntree_grid &lt;- grid_regular(\n  cost_complexity(),\n  tree_depth(),\n  levels = c(5, 3)  \n)\n\ntree_res &lt;- tune_grid(\n  tree_wf,\n  resamples = diab_folds,\n  grid = tree_grid,\n  metrics = metric_set(mn_log_loss)\n)\ntree_res |&gt; collect_metrics()\n\n# A tibble: 15 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0000000001          1 mn_log_loss binary     0.404     5 9.73e-6 pre0_m…\n 2    0.0000000001          8 mn_log_loss binary     0.351     5 1.29e-3 pre0_m…\n 3    0.0000000001         15 mn_log_loss binary     0.347     5 1.29e-3 pre0_m…\n 4    0.0000000178          1 mn_log_loss binary     0.404     5 9.73e-6 pre0_m…\n 5    0.0000000178          8 mn_log_loss binary     0.351     5 1.29e-3 pre0_m…\n 6    0.0000000178         15 mn_log_loss binary     0.347     5 1.29e-3 pre0_m…\n 7    0.00000316            1 mn_log_loss binary     0.404     5 9.73e-6 pre0_m…\n 8    0.00000316            8 mn_log_loss binary     0.351     5 1.29e-3 pre0_m…\n 9    0.00000316           15 mn_log_loss binary     0.347     5 1.29e-3 pre0_m…\n10    0.000562              1 mn_log_loss binary     0.404     5 9.73e-6 pre0_m…\n11    0.000562              8 mn_log_loss binary     0.359     5 3.61e-4 pre0_m…\n12    0.000562             15 mn_log_loss binary     0.359     5 3.61e-4 pre0_m…\n13    0.1                   1 mn_log_loss binary     0.404     5 9.73e-6 pre0_m…\n14    0.1                   8 mn_log_loss binary     0.404     5 9.73e-6 pre0_m…\n15    0.1                  15 mn_log_loss binary     0.404     5 9.73e-6 pre0_m…\n\n# Select best tree\nbest_tree &lt;- select_best(tree_res, metric = \"mn_log_loss\")\nbest_tree\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config         \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;           \n1    0.0000000001         15 pre0_mod03_post0\n\n# Final tree\ntree_final &lt;- tree_wf |&gt;\n  finalize_workflow(best_tree) |&gt;\n  last_fit(diab_split,\n           metrics = metric_set(mn_log_loss, accuracy, roc_auc, brier_class)\n           )\n\ntree_final |&gt; collect_metrics()\n\n# A tibble: 4 × 4\n  .metric     .estimator .estimate .config        \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 accuracy    binary         0.863 pre0_mod0_post0\n2 mn_log_loss binary         0.348 pre0_mod0_post0\n3 roc_auc     binary         0.769 pre0_mod0_post0\n4 brier_class binary         0.104 pre0_mod0_post0\n\n# Confusion matrix for the final tree (test set)\ntree_preds &lt;- tree_final |&gt; collect_predictions()\n\ntree_conf &lt;- tree_preds |&gt;\n  conf_mat(truth = diabetes_binary, estimate = .pred_class)\n\ntree_conf\n\n          Truth\nPrediction     0     1\n         0 64576  9491\n         1   925  1113\n\n# Confusion matrix plot\nautoplot(tree_conf)\n\n\n\n\n\n\n\n# Fit final tree on FULL training data for plotting\ntree_final_full &lt;- tree_wf |&gt;\n  finalize_workflow(best_tree) |&gt;\n  fit(data = diab_train)\n\nfinal_tree_fit &lt;- tree_final_full |&gt;\n  extract_fit_engine()\n\nrpart.plot(\n  final_tree_fit,\n  type = 2,\n  extra = 104,\n  fallen.leaves = TRUE,\n  roundint = FALSE,\n  main = \"Final Classification Tree for Diabetes\"\n)\n\nWarning: labs do not fit even at cex 0.15, there may be some overplotting\n\n\n\n\n\n\n\n\n\n\n\n2.4 Random Forest\n\n# Specify model\nrf_spec &lt;- rand_forest(\n  mtry  = 2,\n  trees = 100,\n  min_n = 5\n) |&gt;\n  set_engine(\"ranger\", importance = \"impurity\") |&gt;\n  set_mode(\"classification\")\n\n# Workflow\nrf_wf &lt;- workflow() |&gt;\n  add_recipe(diab_rec) |&gt;\n  add_model(rf_spec)\n\n# 5-fold CV\nrf_res &lt;- fit_resamples(\n  rf_wf,\n  resamples = diab_folds,\n  metrics   = metric_set(mn_log_loss)\n)\n\nrf_res |&gt; collect_metrics()\n\n# A tibble: 1 × 6\n  .metric     .estimator  mean     n  std_err .config        \n  &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;          \n1 mn_log_loss binary     0.334     5 0.000450 pre0_mod0_post0\n\n# Final RF fit on full training data with evaluation on test set\nrf_final &lt;- rf_wf |&gt;\n  last_fit(diab_split,\n           metrics = metric_set(mn_log_loss, accuracy, roc_auc, brier_class)\n           )\n\nrf_final |&gt; collect_metrics()\n\n# A tibble: 4 × 4\n  .metric     .estimator .estimate .config        \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 accuracy    binary         0.864 pre0_mod0_post0\n2 mn_log_loss binary         0.333 pre0_mod0_post0\n3 roc_auc     binary         0.795 pre0_mod0_post0\n4 brier_class binary         0.102 pre0_mod0_post0\n\n# Confusion matrix\nrf_preds &lt;- rf_final |&gt; collect_predictions()\n\nrf_conf &lt;- rf_preds |&gt;\n  conf_mat(truth = diabetes_binary, estimate = .pred_class)\n\nrf_conf\n\n          Truth\nPrediction     0     1\n         0 65126 10009\n         1   375   595\n\n# Confusion matrix plot\nautoplot(rf_conf)\n\n\n\n\n\n\n\n# Fit RF on FULL training data for importance\nrf_full &lt;- rf_wf |&gt;\n  fit(data = diab_train)\n\nrf_engine &lt;- rf_full |&gt;\n  extract_fit_engine()\n\nvip(\n  rf_engine,\n  num_features = 5,\n  main = \"Variable Importance from Random Forest\"\n)\n\n\n\n\n\n\n\n\n\n\n2.5 Comparing Model Results\nA comparison of classification Tree and Random Forest Models shows that the Random Forest Model slightly outperforms across all metrics. Most importantly, the Random Forest model achieved a lower log-loss, with 0.3334360 for Random Forest and 0.3483469 for the Classification Tree.\nThe random forest also performed better across other metrics, achieving lower test-set Brier score (0.1018 vs. 0.1037), higher ROC AUC (0.795 vs. 0.769), and slightly higher accuracy (0.8636 vs. 0.8631).\nBased on these results the Random Forest Model was selected as the final model to be used in the API component of this project.\n\ntree_logloss &lt;- tree_final |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"Classification Tree\") |&gt;\n  select(model, .metric, .estimate)\n\nrf_logloss &lt;- rf_final |&gt;\n  collect_metrics() |&gt;\n  mutate(model = \"Random Forest\") |&gt;\n  select(model, .metric, .estimate)\n\nlogloss_comparison &lt;- bind_rows(tree_logloss, rf_logloss)\n\nlogloss_comparison\n\n# A tibble: 8 × 3\n  model               .metric     .estimate\n  &lt;chr&gt;               &lt;chr&gt;           &lt;dbl&gt;\n1 Classification Tree accuracy        0.863\n2 Classification Tree mn_log_loss     0.348\n3 Classification Tree roc_auc         0.769\n4 Classification Tree brier_class     0.104\n5 Random Forest       accuracy        0.864\n6 Random Forest       mn_log_loss     0.333\n7 Random Forest       roc_auc         0.795\n8 Random Forest       brier_class     0.102"
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "ST 558 - Final Project",
    "section": "",
    "text": "This project explores data on Diabetes. The original data were obtained from the CDC’s Behavioral Risk Factor Surveillance System (BRFSS), a health-related telephone survey that is collected annually by the CDC. The data contain self-reported health and lifestyle information and include 22 variables related to chronic disease, physical activity, general health, demographics, and access to health care. The primary outcome of interest in this project is ‘Diabetes_binary’, a binary indicator where:\n\n0 = No diabetes\n1 = Diabetes\n\nThe majority of remaining variables are coded as binary (0/1) indicators (e.g., HighBP, HighChol, Stroke, Smoker), with some coded as ordinal categories (e.g., Age, Education, Income) or counts (e.g., MentHlth, PhysHlth).\nFor this project, a csv of the data available on Kaggle for the year 2015 was used. The data contain 253,680 responses.\nThis project consists of two sections:\n\nExploratory Data Analysis\n\nThe purpose of Exploratory Data Analysis is to better understand the structure of the data and how the data are stored. We will conduct basic data validation, including determining the number and type of variables included and whether there are missing values. The data will be cleaned and transformed/formatted to prepare it for exploratory analysis and modeling. Additionally, distributions and relationships between variables will be investigated to inform modeling.\n\nModeling\n\nThe purpose of the modeling section is to build and evaluate two predictive models that classify individuals as having diabetes or not, based on demographic, behavioral, and health-related variables explored in this EDA section. A classification tree and a random forest model will be constructed and compared in tidymodels, with the goal of selecting the best predictive model for the data.\nClick here for the Modeling Page."
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "ST 558 - Final Project",
    "section": "",
    "text": "This project explores data on Diabetes. The original data were obtained from the CDC’s Behavioral Risk Factor Surveillance System (BRFSS), a health-related telephone survey that is collected annually by the CDC. The data contain self-reported health and lifestyle information and include 22 variables related to chronic disease, physical activity, general health, demographics, and access to health care. The primary outcome of interest in this project is ‘Diabetes_binary’, a binary indicator where:\n\n0 = No diabetes\n1 = Diabetes\n\nThe majority of remaining variables are coded as binary (0/1) indicators (e.g., HighBP, HighChol, Stroke, Smoker), with some coded as ordinal categories (e.g., Age, Education, Income) or counts (e.g., MentHlth, PhysHlth).\nFor this project, a csv of the data available on Kaggle for the year 2015 was used. The data contain 253,680 responses.\nThis project consists of two sections:\n\nExploratory Data Analysis\n\nThe purpose of Exploratory Data Analysis is to better understand the structure of the data and how the data are stored. We will conduct basic data validation, including determining the number and type of variables included and whether there are missing values. The data will be cleaned and transformed/formatted to prepare it for exploratory analysis and modeling. Additionally, distributions and relationships between variables will be investigated to inform modeling.\n\nModeling\n\nThe purpose of the modeling section is to build and evaluate two predictive models that classify individuals as having diabetes or not, based on demographic, behavioral, and health-related variables explored in this EDA section. A classification tree and a random forest model will be constructed and compared in tidymodels, with the goal of selecting the best predictive model for the data.\nClick here for the Modeling Page."
  },
  {
    "objectID": "EDA.html#exploratory-data-analysis",
    "href": "EDA.html#exploratory-data-analysis",
    "title": "ST 558 - Final Project",
    "section": "1. Exploratory Data Analysis",
    "text": "1. Exploratory Data Analysis\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readxl)\nlibrary(psych)\n\n\nAttaching package: 'psych'\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(skimr)\nlibrary(ggplot2)\nlibrary(forcats)\n\n# read in data and clean col names\ndata &lt;- read.csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\",header=TRUE) |&gt;\n  clean_names()\nview(data)\n\n# explore structure and variable types\nstr(data)\n\n'data.frame':   253680 obs. of  22 variables:\n $ diabetes_binary       : num  0 0 0 0 0 0 0 0 1 0 ...\n $ high_bp               : num  1 0 1 1 1 1 1 1 1 0 ...\n $ high_chol             : num  1 0 1 0 1 1 0 1 1 0 ...\n $ chol_check            : num  1 0 1 1 1 1 1 1 1 1 ...\n $ bmi                   : num  40 25 28 27 24 25 30 25 30 24 ...\n $ smoker                : num  1 1 0 0 0 1 1 1 1 0 ...\n $ stroke                : num  0 0 0 0 0 0 0 0 0 0 ...\n $ heart_diseaseor_attack: num  0 0 0 0 0 0 0 0 1 0 ...\n $ phys_activity         : num  0 1 0 1 1 1 0 1 0 0 ...\n $ fruits                : num  0 0 1 1 1 1 0 0 1 0 ...\n $ veggies               : num  1 0 0 1 1 1 0 1 1 1 ...\n $ hvy_alcohol_consump   : num  0 0 0 0 0 0 0 0 0 0 ...\n $ any_healthcare        : num  1 0 1 1 1 1 1 1 1 1 ...\n $ no_docbc_cost         : num  0 1 1 0 0 0 0 0 0 0 ...\n $ gen_hlth              : num  5 3 5 2 2 2 3 3 5 2 ...\n $ ment_hlth             : num  18 0 30 0 3 0 0 0 30 0 ...\n $ phys_hlth             : num  15 0 30 0 0 2 14 0 30 0 ...\n $ diff_walk             : num  1 0 1 0 0 0 0 1 1 0 ...\n $ sex                   : num  0 0 0 0 0 1 0 0 0 1 ...\n $ age                   : num  9 7 9 11 11 10 9 11 9 8 ...\n $ education             : num  4 6 4 3 5 6 6 4 5 4 ...\n $ income                : num  3 1 8 6 4 8 7 4 1 3 ...\n\nhead(data)\n\n  diabetes_binary high_bp high_chol chol_check bmi smoker stroke\n1               0       1         1          1  40      1      0\n2               0       0         0          0  25      1      0\n3               0       1         1          1  28      0      0\n4               0       1         0          1  27      0      0\n5               0       1         1          1  24      0      0\n6               0       1         1          1  25      1      0\n  heart_diseaseor_attack phys_activity fruits veggies hvy_alcohol_consump\n1                      0             0      0       1                   0\n2                      0             1      0       0                   0\n3                      0             0      1       0                   0\n4                      0             1      1       1                   0\n5                      0             1      1       1                   0\n6                      0             1      1       1                   0\n  any_healthcare no_docbc_cost gen_hlth ment_hlth phys_hlth diff_walk sex age\n1              1             0        5        18        15         1   0   9\n2              0             1        3         0         0         0   0   7\n3              1             1        5        30        30         1   0   9\n4              1             0        2         0         0         0   0  11\n5              1             0        2         3         0         0   0  11\n6              1             0        2         0         2         0   1  10\n  education income\n1         4      3\n2         6      1\n3         4      8\n4         3      6\n5         5      4\n6         6      8\n\nglimpse(data)\n\nRows: 253,680\nColumns: 22\n$ diabetes_binary        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,…\n$ high_bp                &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,…\n$ high_chol              &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,…\n$ chol_check             &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ bmi                    &lt;dbl&gt; 40, 25, 28, 27, 24, 25, 30, 25, 30, 24, 25, 34,…\n$ smoker                 &lt;dbl&gt; 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,…\n$ stroke                 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,…\n$ heart_diseaseor_attack &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,…\n$ phys_activity          &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,…\n$ fruits                 &lt;dbl&gt; 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,…\n$ veggies                &lt;dbl&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,…\n$ hvy_alcohol_consump    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ any_healthcare         &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ no_docbc_cost          &lt;dbl&gt; 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,…\n$ gen_hlth               &lt;dbl&gt; 5, 3, 5, 2, 2, 2, 3, 3, 5, 2, 3, 3, 3, 4, 4, 2,…\n$ ment_hlth              &lt;dbl&gt; 18, 0, 30, 0, 3, 0, 0, 0, 30, 0, 0, 0, 0, 0, 30…\n$ phys_hlth              &lt;dbl&gt; 15, 0, 30, 0, 0, 2, 14, 0, 30, 0, 0, 30, 15, 0,…\n$ diff_walk              &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,…\n$ sex                    &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,…\n$ age                    &lt;dbl&gt; 9, 7, 9, 11, 11, 10, 9, 11, 9, 8, 13, 10, 7, 11…\n$ education              &lt;dbl&gt; 4, 6, 4, 3, 5, 6, 6, 4, 5, 4, 6, 5, 5, 4, 6, 6,…\n$ income                 &lt;dbl&gt; 3, 1, 8, 6, 4, 8, 7, 4, 1, 3, 8, 1, 7, 6, 2, 8,…\n\n# basic data cleaning\n# convert to factors\nnames(data)\n\n [1] \"diabetes_binary\"        \"high_bp\"                \"high_chol\"             \n [4] \"chol_check\"             \"bmi\"                    \"smoker\"                \n [7] \"stroke\"                 \"heart_diseaseor_attack\" \"phys_activity\"         \n[10] \"fruits\"                 \"veggies\"                \"hvy_alcohol_consump\"   \n[13] \"any_healthcare\"         \"no_docbc_cost\"          \"gen_hlth\"              \n[16] \"ment_hlth\"              \"phys_hlth\"              \"diff_walk\"             \n[19] \"sex\"                    \"age\"                    \"education\"             \n[22] \"income\"                \n\nvar_factors &lt;- c(\"diabetes_binary\", \"high_bp\", \"high_chol\", \"chol_check\",\n\"smoker\", \"stroke\", \"heart_diseaseor_attack\",\n\"phys_activity\", \"fruits\", \"veggies\", \"hvy_alcohol_consump\",\n\"any_healthcare\", \"no_docbc_cost\", \"gen_hlth\", \"ment_hlth\",\n\"phys_hlth\", \"diff_walk\", \"sex\", \"age\", \"education\", \"income\")\ndata &lt;- data |&gt;\nmutate(across(all_of(var_factors), as.factor))\n\n# clean factor labels for select variables\ndata &lt;- data |&gt;\n  mutate(\n    high_bp = fct_recode(high_bp, \"No\" = \"0\", \"Yes\" = \"1\"),\n    high_chol = fct_recode(high_chol, \"No\" = \"0\", \"Yes\" = \"1\"),\n    phys_activity = fct_recode(phys_activity, \"No\" = \"0\", \"Yes\" = \"1\"),\n    diff_walk = fct_recode(diff_walk, \"No\" = \"0\", \"Yes\" = \"1\"),\n    heart_diseaseor_attack = fct_recode(heart_diseaseor_attack, \"No\" = \"0\", \"Yes\" = \"1\"),\n    diabetes_binary = fct_recode(diabetes_binary, \"No\" = \"0\", \"Yes\" = \"1\")\n  )\n\n\n1.1 Missing data\nMissing data was assessed below. No missing values were found in the data.\n\n# explore missing data\n# explore missing values\nsum(is.na(data))\n\n[1] 0\n\n# set up a function to check NA values by column\nsum_na &lt;- function(column){\n  sum(is.na(column))\n}\nsum_na(data)\n\n[1] 0\n\n#for student_por, across all columns, run my function, sum na\nna_counts &lt;- data |&gt;\n  summarize(across(everything(), sum_na))\n#na_counts\n\n\n\n1.2 Response Variable\nThe response variable is diabetes_binary. The majority of individuals reported no diabetes: 218,334 individuals reported no diabetes, while 35,346 individuals reported diabetes.\n\n#table(data$diabetes_binary)\ndata |&gt;\ncount(diabetes_binary) |&gt;\nmutate(prop = n / sum(n))\n\n  diabetes_binary      n     prop\n1              No 218334 0.860667\n2             Yes  35346 0.139333\n\ndata |&gt; \n  ggplot(aes(x = diabetes_binary)) +\n  geom_bar(fill = \"blue\") +\n  labs(title = \"Distribution of Diabetes Status\",\n    x = \"Diabetes\", y = \"Count\")\n\n\n\n\n\n\n\n\n\n\n1.3 Predictor Variables\n\n1.3.1 Binary Variables\nAssociations between all binary variables and diabetes were evaluated. The strongest associations appeared between diabetes and high blood pressure, high cholesterol, heart disease or attack status, physical activity, and difficulty walking. Proportions are available below, and the appendix contains additional visuals for variables with weaker associations (e.g. fruits, sex, etc.)\n\n# High BP\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"High Blood Pressure\" = data$high_bp\n)\n\n               High Blood Pressure\nDiabetes Binary     No    Yes\n            No  136109  82225\n            Yes   8742  26604\n\nggplot(data, aes(x = high_bp, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by High Blood Pressure\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n# High Chol\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"High Cholesterol\" = data$high_chol\n)\n\n               High Cholesterol\nDiabetes Binary     No    Yes\n            No  134429  83905\n            Yes  11660  23686\n\nggplot(data, aes(x = high_chol, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by High Cholesterol\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n# Stroke\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"Stroke\" = data$stroke\n)\n\n               Stroke\nDiabetes Binary      0      1\n            No  211310   7024\n            Yes  32078   3268\n\nggplot(data, aes(x = stroke, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by Stroke Status\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n# heart_diseaseor_attack\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"Heart Disease or Attack\" = data$heart_diseaseor_attack\n)\n\n               Heart Disease or Attack\nDiabetes Binary     No    Yes\n            No  202319  16015\n            Yes  27468   7878\n\nggplot(data, aes(x = heart_diseaseor_attack, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by Heart Disease or Attack Status\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n#diff_walk\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"Difficulty Walking\" = data$diff_walk\n)\n\n               Difficulty Walking\nDiabetes Binary     No    Yes\n            No  188780  29554\n            Yes  22225  13121\n\nggplot(data, aes(x = diff_walk, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by Difficulty Walking\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n#phys_activity\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"Physical Activity in Past 30 Days\" = data$phys_activity\n)\n\n               Physical Activity in Past 30 Days\nDiabetes Binary     No    Yes\n            No   48701 169633\n            Yes  13059  22287\n\nggplot(data, aes(x = phys_activity, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by Phys Activity Status\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n\n\n\n1.3.2 Numeric Variables\nAmong the number/continuous variables we looked at the relationship between Diabetes Status and Body Mass Index, Physical Health and Mental Health. Plots and tables below indicate that individuals with Diabetes tend to have a higher mean and median BMI. Physical Health was measured as the number of days in the past month when physical health was not good. Individuals with diabetes reported more days of poor physical health. Mental health was measured as the number of days in the past month when mental health was not good. Individuals with diabetes reported slightly more days of poor mental health, but this relationship was much weaker.\n\n# BMI\nggplot(data, aes(x = bmi, fill = diabetes_binary)) +\n  geom_histogram(alpha = 0.5, position = \"identity\", bins = 40) +\n  labs(title = \"BMI Distribution by Diabetes Status\",\n       x = \"BMI\", \n       y = \"Count\",\n       fill = \"Diabetes Status\")\n\n\n\n\n\n\n\nggplot(data, aes(x = diabetes_binary, y = bmi, fill = diabetes_binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"BMI by Diabetes Status\",\n    x = \"Diabetes Status\",\n    y = \"BMI\",\n    fill = \"Diabetes Status\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nbmi_summary &lt;- data |&gt;\n  group_by(diabetes_binary) |&gt;\n  summarize(\n    n = n(),\n    mean_bmi   = mean(bmi),\n    median_bmi = median(bmi),\n    sd_bmi     = sd(bmi)\n  )\n\nbmi_summary\n\n# A tibble: 2 × 5\n  diabetes_binary      n mean_bmi median_bmi sd_bmi\n  &lt;fct&gt;            &lt;int&gt;    &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n1 No              218334     27.8         27   6.29\n2 Yes              35346     31.9         31   7.36\n\n# ment_health and phys_health\ndata &lt;- data |&gt;\n  mutate(\n    ment_hlth_num = as.numeric(as.character(ment_hlth)),\n    phys_hlth_num = as.numeric(as.character(phys_hlth))\n  )\nggplot(data, aes(x = diabetes_binary, y = ment_hlth_num, fill = diabetes_binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Days of Poor Mental Health by Diabetes Status\",\n    x = \"Diabetes Status\",\n    y = \"Poor Mental Health Days (0–30)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nggplot(data, aes(x = diabetes_binary, y = phys_hlth_num, fill = diabetes_binary)) +\n  geom_boxplot() +\n  labs(\n    title = \"Days of Poor Physical Health by Diabetes Status\",\n    x = \"Diabetes Status\",\n    y = \"Poor Physical Health Days (0–30)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\nment_phys_summary &lt;- data |&gt;\n  group_by(diabetes_binary) |&gt;\n  summarize(\n    mean_ment_hlth = mean(ment_hlth_num, na.rm = TRUE),\n    median_ment_hlth = median(ment_hlth_num, na.rm = TRUE),\n    mean_phys_hlth = mean(phys_hlth_num, na.rm = TRUE),\n    median_phys_hlth = median(phys_hlth_num, na.rm = TRUE)\n  )\n\nment_phys_summary\n\n# A tibble: 2 × 5\n  diabetes_binary mean_ment_hlth median_ment_hlth mean_phys_hlth\n  &lt;fct&gt;                    &lt;dbl&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1 No                        2.98                0           3.64\n2 Yes                       4.46                0           7.95\n# ℹ 1 more variable: median_phys_hlth &lt;dbl&gt;\n\n# Correlation matrix with numeric vars\nnumeric_vars &lt;- data |&gt; \n  mutate(\n    age_num = as.numeric(age),\n    diabetes_num = as.numeric(diabetes_binary) - 1\n  ) |&gt;\n  select(bmi, phys_hlth_num, ment_hlth_num, age_num, diabetes_num)\n\ncor(numeric_vars, use = \"complete.obs\")\n\n                      bmi phys_hlth_num ment_hlth_num     age_num diabetes_num\nbmi            1.00000000    0.12114111    0.08531016 -0.03661764   0.21684306\nphys_hlth_num  0.12114111    1.00000000    0.35361887  0.09912993   0.17133670\nment_hlth_num  0.08531016    0.35361887    1.00000000 -0.09206802   0.06931508\nage_num       -0.03661764    0.09912993   -0.09206802  1.00000000   0.17744187\ndiabetes_num   0.21684306    0.17133670    0.06931508  0.17744187   1.00000000\n\n\n\n\n1.3.3 Ordinal Variables\nOrdinal variables included Age, General Health (self-rated), Income, and Education.\nDiabetes prevalence appears to increase steadily across Age groups. Similarly, a strong patterns is present in General Health. Individuals rating their health as “Fair” or “Poor” show higher diabetes prevalence than those reporting “Good,” “Very Good,” or “Excellent” general health. Income also shows a clear inverse relationship with diabetes, with lower-income categories showing higher diabetes prevalence. Education shows a slight pattern with a modest decrease in diabetes prevalence with higher educational attainment, but the differences between adjacent categories are smaller than those seen for age, general health, or income.\nOverall, the ordinal variables display relationships with diabetes prevalence, particularly age and general health.\n\n# Convert ordinal vars to ordered factors with labels\ndata &lt;- data |&gt;\n  mutate(\n    age = fct_recode(age,\n                     \"18–24\" = \"1\", \"25–29\" = \"2\", \"30–34\" = \"3\", \"35–39\" = \"4\",\n                     \"40–44\" = \"5\", \"45–49\" = \"6\", \"50–54\" = \"7\", \"55–59\" = \"8\",\n                     \"60–64\" = \"9\", \"65–69\" = \"10\", \"70–74\" = \"11\", \"75–79\" = \"12\",\n                     \"80+\" = \"13\"),\n    age = fct_relevel(age, \n                      \"18–24\",\"25–29\",\"30–34\",\"35–39\",\"40–44\",\"45–49\",\"50–54\",\n                      \"55–59\",\"60–64\",\"65–69\",\"70–74\",\"75–79\",\"80+\"),\n    \n    gen_hlth = fct_recode(gen_hlth,\n                          \"Excellent\" = \"1\",\n                          \"Very Good\" = \"2\",\n                          \"Good\" = \"3\",\n                          \"Fair\" = \"4\",\n                          \"Poor\" = \"5\"),\n    gen_hlth = fct_relevel(gen_hlth,\n                           \"Excellent\",\"Very Good\",\"Good\",\"Fair\",\"Poor\"),\n    \n    education = fct_recode(education,\n                           \"Never attended\" = \"1\",\n                           \"Elementary\" = \"2\",\n                           \"Some high school\" = \"3\",\n                           \"High school grad\" = \"4\",\n                           \"Some college\" = \"5\",\n                           \"College graduate\" = \"6\"),\n    \n    income = fct_recode(income,\n                        \"&lt;$10k\" = \"1\", \"$10–15k\" = \"2\", \"$15–20k\" = \"3\",\n                        \"$20–25k\" = \"4\", \"$25–35k\" = \"5\", \"$35–50k\" = \"6\",\n                        \"$50–75k\" = \"7\", \"&gt;$75k\" = \"8\")\n  )\n\n# Age\nggplot(data, aes(x = age, fill = diabetes_binary)) +\n  geom_bar(position = \"fill\") +\n  labs(\n    title = \"Proportion of Diabetes by Age Group\",\n    x = \"Age Group\",\n    y = \"Proportion\"\n  ) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_minimal()\n\n\n\n\n\n\n\n# General Health\nggplot(data, aes(x = gen_hlth, fill = diabetes_binary)) +\n  geom_bar(position = \"fill\") +\n  labs(\n    title = \"Diabetes Proportion by Self-Rated General Health\",\n    x = \"General Health Rating\",\n    y = \"Proportion\"\n  ) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_minimal()\n\n\n\n\n\n\n\n# Education\nggplot(data, aes(x = education, fill = diabetes_binary)) +\n  geom_bar(position = \"fill\") +\n  labs(\n    title = \"Proportion of Diabetes by Education Level\",\n    x = \"Education Level\",\n    y = \"Proportion\"\n  ) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_minimal()\n\n\n\n\n\n\n\n# Income\nggplot(data, aes(x = income, fill = diabetes_binary)) +\n  geom_bar(position = \"fill\") +\n  labs(\n    title = \"Proportion of Diabetes by Income Category\",\n    x = \"Income Level\",\n    y = \"Proportion\"\n  ) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n1.4 Summary\nAmong the variables that were assessed, many showed interesting relationships with Diabetes prevalence. Among binary variables, high blood pressure, high cholesterol, heart disease or attack status, physical activity, and difficulty walking all showed relationships with diabetes prevalence. Among numeric variables, BMI and physical health showed the strongest relationships. Among ordinal variables, age and general health appeared to have stronger relations with diabetes that other ordinal variables.\nIn section 2 we will proceed to construct two models using selected variables from the aforementioned data. Click here for the Modeling Page"
  },
  {
    "objectID": "EDA.html#appendix",
    "href": "EDA.html#appendix",
    "title": "ST 558 - Final Project",
    "section": "Appendix",
    "text": "Appendix\n\n# Binary Variables with weak associations\n# Smoker\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"Smoker\" = data$smoker\n)\n\n               Smoker\nDiabetes Binary      0      1\n            No  124228  94106\n            Yes  17029  18317\n\nggplot(data, aes(x = smoker, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by Smoker Status\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n# Chol Check\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"Cholesterol Check\" = data$chol_check\n)\n\n               Cholesterol Check\nDiabetes Binary      0      1\n            No    9229 209105\n            Yes    241  35105\n\nggplot(data, aes(x = chol_check, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by Cholesterol Check Status\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n#fruits\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"Fruit Consumption\" = data$fruits\n)\n\n               Fruit Consumption\nDiabetes Binary      0      1\n            No   78129 140205\n            Yes  14653  20693\n\nggplot(data, aes(x = fruits, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by Fruit Consumption Status\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n#veggies\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"Vegetable Consumption\" = data$veggies\n)\n\n               Vegetable Consumption\nDiabetes Binary      0      1\n            No   39229 179105\n            Yes   8610  26736\n\nggplot(data, aes(x = veggies, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by Vegetable Consumption Status\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n#hvy_alcohol_consump\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"Heavy Alcohol Consumption\" = data$hvy_alcohol_consump\n)\n\n               Heavy Alcohol Consumption\nDiabetes Binary      0      1\n            No  204910  13424\n            Yes  34514    832\n\nggplot(data, aes(x = hvy_alcohol_consump, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by Alcohol Consumption Status\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n#any_healthcare\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"Have any kind of health caverage\" = data$any_healthcare\n)\n\n               Have any kind of health caverage\nDiabetes Binary      0      1\n            No   10995 207339\n            Yes   1422  33924\n\nggplot(data, aes(x = any_healthcare, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by Health Care Status\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n#no_docbc_cost\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"Did not see Doctor bc of cost\" = data$no_docbc_cost\n)\n\n               Did not see Doctor bc of cost\nDiabetes Binary      0      1\n            No  200722  17612\n            Yes  31604   3742\n\nggplot(data, aes(x = no_docbc_cost, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by No Doctor bc Cost Status\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n#sex\ntable(\n  \"Diabetes Binary\" = data$diabetes_binary,\n  \"Sex\" = data$sex\n)\n\n               Sex\nDiabetes Binary      0      1\n            No  123563  94771\n            Yes  18411  16935\n\nggplot(data, aes(x = sex, fill = diabetes_binary)) +\ngeom_bar(position = \"fill\") +\nlabs(title = \"Proportion of Diabetes by Sex\",\ny = \"Proportion\")\n\n\n\n\n\n\n\n# Age and Sex\nlibrary(dplyr)\n\n# Convert diabetes_binary to numeric 0/1\ndata &lt;- data |&gt;\n  mutate(diabetes_num = as.numeric(diabetes_binary) - 1)\n\n# Summaries by age and sex\nage_diabetes_summary &lt;- data |&gt;\n  group_by(age, sex) |&gt;\n  summarize(\n    mean = mean(diabetes_num),\n    median = median(diabetes_num),\n    sd = sd(diabetes_num),\n    IQR = IQR(diabetes_num),\n    min = min(diabetes_num),\n    max = max(diabetes_num)\n  )\n\n`summarise()` has grouped output by 'age'. You can override using the `.groups`\nargument.\n\nage_diabetes_summary\n\n# A tibble: 26 × 8\n# Groups:   age [13]\n   age   sex     mean median    sd   IQR   min   max\n   &lt;fct&gt; &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 18–24 0     0.0164      0 0.127     0     0     1\n 2 18–24 1     0.0112      0 0.105     0     0     1\n 3 25–29 0     0.0223      0 0.148     0     0     1\n 4 25–29 1     0.0141      0 0.118     0     0     1\n 5 30–34 0     0.0315      0 0.175     0     0     1\n 6 30–34 1     0.0243      0 0.154     0     0     1\n 7 35–39 0     0.0474      0 0.212     0     0     1\n 8 35–39 1     0.0426      0 0.202     0     0     1\n 9 40–44 0     0.0630      0 0.243     0     0     1\n10 40–44 1     0.0677      0 0.251     0     0     1\n# ℹ 16 more rows\n\nview(age_diabetes_summary)\n\nage_diabetes_summary |&gt; \n  ggplot(aes(x = age, y = mean, fill = sex)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Diabetes Prevalence by Age Group and Sex\",\n    x = \"Age Group\",\n    y = \"Prevalence of Diabetes\",\n    fill = \"Sex\"\n  ) +\n  scale_y_continuous(labels = scales::percent) +\n  theme_minimal()"
  }
]